{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from math import factorial\n",
    "from scipy.misc import *\n",
    "from scipy.special import factorial2\n",
    "import math\n",
    "from scipy.special import eval_hermite as H\n",
    "from scipy.special import binom\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from scipy.special import wofz\n",
    "from pathos.multiprocessing import ProcessingPool as pool\n",
    "import dask.array as da\n",
    "\n",
    "##\n",
    "import dask\n",
    "from dask import delayed\n",
    "import dask.dataframe as dd\n",
    "import dask.array as dp\n",
    "from dask.distributed import Client, progress\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(processes=False, threads_per_worker=2,\n",
    "                 n_workers=1, memory_limit='2GB')\n",
    "# dask.config.set(scheduler='threads')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def temp1(x,i):\n",
    "    return x*(i+1)\n",
    "\n",
    "@dask.delayed\n",
    "def temp2(x,y):\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 253 ms, sys: 15.4 ms, total: 269 ms\n",
      "Wall time: 275 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3999999.999999837"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "x = dp.asarray(np.linspace(0,1,n))\n",
    "total=[]\n",
    "for i in range(2):\n",
    "    x=temp1(x,i)\n",
    "    x=temp2(x,x)\n",
    "total=dask.delayed(sum)(x)\n",
    "\n",
    "# print(total.compute())\n",
    "# total.visualize()\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39999.99999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999999.999999837\n",
      "CPU times: user 241 ms, sys: 6.82 ms, total: 248 ms\n",
      "Wall time: 252 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x =(np.linspace(0,1,n))\n",
    "def temp1(x,i):\n",
    "    return x*(i+1)\n",
    "\n",
    "def temp2(x,y):\n",
    "    return x+y\n",
    "total=[]\n",
    "for i in range(2):\n",
    "    x=temp1(x,i)\n",
    "    x=temp2(x,x)\n",
    "total=sum(x)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# client = Client(processes=False, threads_per_worker=4,\n",
    "#                  n_workers=1, memory_limit='2GB')\n",
    "dask.config.set(scheduler='threads')\n",
    "dict = { 'problem_type': 'rixs',\n",
    "        'method': 'gf',\n",
    "        'maxt' : 200,\n",
    "        'nstep': 1000,\n",
    "         \"nf\": 10.0,\n",
    "         \"energy_ex\": 10.0,\n",
    "         \"omega_in\": 10.0,\n",
    "         \"gamma\": 0.105,\n",
    "         \"gamma_ph\": 0.05,\n",
    "         \"alpha_exp\": 0.01 }\n",
    "\n",
    "t=(np.linspace(0.,dict['maxt'],int(dict['nstep'])))\n",
    "\n",
    "\n",
    "# read dataframe\n",
    "q_points = np.loadtxt('q_sampling.csv')\n",
    "q_weights = np.loadtxt('q_weights.csv')\n",
    "q_coupling = np.loadtxt('q_coupling.csv')\n",
    "q_phonon = np.loadtxt('q_phonon.csv')\n",
    "q_strength = (q_coupling/q_phonon)**2\n",
    "\n",
    "#\n",
    "q_points = dp.asarray(q_points)\n",
    "q_weights = dp.asarray(q_weights)\n",
    "q_coupling = dp.asarray(q_coupling)\n",
    "q_phonon = dp.asarray(q_phonon)\n",
    "q_strength = dp.asarray(q_strength)\n",
    "t = dp.asarray(t)\n",
    "\n",
    "\n",
    "def fkq():\n",
    "    Fkq=1.\n",
    "    for gkqi,omegaqi,wi in zip(q_strength,\\\n",
    "                        q_phonon*2*np.pi,q_weights):\n",
    "        cumulant = \\\n",
    "            gkqi*(np.exp(-1.j*omegaqi*t)+1.j*omegaqi*t-1)*wi/len(q_points)\n",
    "        Fkq=Fkq*np.exp(cumulant)\n",
    "    return Fkq\n",
    "\n",
    "print('Eph', q_phonon )\n",
    "cumulant_kq = fkq()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @dask.delayed\n",
    "\n",
    "\n",
    "# @dask.delayed\n",
    "def multi_phonon(qmap,nph):\n",
    "    G=-1.j*np.exp(-1.j*(np.pi*2.*dict['energy_ex'])*t)\n",
    "    D=1.\n",
    "    print('here')\n",
    "    for n in range(nph):\n",
    "        Dk=(np.sqrt(q_strength[qmap[n]]))*(np.exp(-1.j*q_phonon[qmap[n]]*2.*np.pi*t)-1.)\n",
    "        D=D*Dk\n",
    "\n",
    "    G=G*(D)/np.sqrt(factorial(nph))\n",
    "    G=G*cumulant_kq*np.exp(-2*np.pi*dict['gamma']*t)\n",
    "    # das\n",
    "    # G = dp.asarray(G)\n",
    "\n",
    "    intx=goertzel(G,dict['nstep']/dict['maxt'],dict['omega_in'])\n",
    "\n",
    "    return abs(intx[0])**2\n",
    "\n",
    "#@dask.delayed\n",
    "def goertzel(samples, sample_rate, freqs):\n",
    "    window_size = len(samples)\n",
    "    f_step = sample_rate / float(window_size)\n",
    "    f_step_normalized = 1./ window_size\n",
    "    kx=int(math.floor(freqs / f_step))\n",
    "    n_range = range(0, window_size)\n",
    "    freq = [];power=[]\n",
    "    f = kx * f_step_normalized\n",
    "    w_real = math.cos(2.0 * math.pi * f)\n",
    "    w_imag = math.sin(2.0 * math.pi * f)\n",
    "    dr1, dr2 = 0.0, 0.0\n",
    "    di1,di2 = 0.0, 0.0\n",
    "    for n in n_range:\n",
    "        yrt  = samples[n].real + 2*w_real*dr1-dr2\n",
    "        dr2, dr1 = dr1, yrt\n",
    "        yit  = samples[n].imag + 2*w_real * di1 - di2\n",
    "        di2, di1 = di1, yit\n",
    "    yr=dr1*w_real-dr2+1.j*w_imag*dr1\n",
    "    yi=di1*w_real-di2+1.j*w_imag*di1\n",
    "    y=(1.j*yr+yi)/(window_size)\n",
    "    power.append(abs(y))\n",
    "    freq.append(freqs)\n",
    "    return  (power)\n",
    "\n",
    "\n",
    "\n",
    "loss=[];r=[]\n",
    "\n",
    "\n",
    "r = multi_phonon([0],1)\n",
    "# r.vizualize()\n",
    "\n",
    "# for nph in tqdm(range(int(dict['nf']))):\n",
    "#     if nph==0:\n",
    "#         print('0 phonon : ')\n",
    "#         qmap=[0]\n",
    "#         loss_temp,r_temp=[nph],[multi_phonon(qmap,nph)]\n",
    "#     elif nph==1:\n",
    "#         print('1 phonon : ')\n",
    "#         qmap=[0]\n",
    "#         loss_temp,r_temp=[q_phonon[qmap[0]]*nph],[q_weights[0]*multi_phonon(qmap,1)]\n",
    "#     loss.extend(loss_temp)\n",
    "#     r.extend(r_temp)\n",
    "print('############## ouput ####')\n",
    "print(r.compute())\n",
    "client.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decorator",
   "language": "python",
   "name": "decorator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
